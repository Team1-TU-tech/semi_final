services:

  spark-master:  # Spark 마스터 서비스 정의
    image: apache/spark:latest  
    container_name: spark-master
    hostname: spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master  
    environment:  
      - SPARK_MASTER_HOST=spark-master
      - SPARK_DRIVER_MEMORY=1G  # 마스터의 메모리를 1GB로 설정
      - TZ=Asia/Seoul
    volumes:
      - ./metrics.properties:/opt/spark/conf/metrics.properties
    ports:
      - "8080:8080"  # 로컬 포트 8080을 컨테이너의 포트 8080과 연결 (Spark Web UI)
      - "7077:7077"  # 로컬 포트 7077을 컨테이너의 포트 7077과 연결 (Spark 마스터 포트)
    networks:
      - spark-net

  spark-worker:  # Spark 워커 서비스 정의
    image: apache/spark:latest
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_CORES=1  # 워커가 사용할 CPU 코어 수를 1개로 제한
      - SPARK_WORKER_MEMORY=1G  # 워커가 사용할 메모리를 1GB로 제한
      - TZ=Asia/Seoul
    depends_on:
      - spark-master  # spark-master 서비스가 먼저 시작되도록 지정
    networks:
      - spark-net  # 'spark-net' 네트워크에 연결하여 Spark 클러스터 내부 통신
    deploy:
      replicas: 3  # 워커의 수를 3개로 설정 (스케일 조정 가능)

  spark-submit:  # Spark Submit 서비스 정의
    image: apache/spark:latest
    container_name: spark-submit
    environment:
      - TZ=Asia/Seoul
    networks:
      - spark-net  # 'spark-net' 네트워크에 연결하여 Spark 클러스터 내부 통신
    depends_on:
      - spark-master
      - spark-worker
    volumes:
      - ./app:/app  # 로컬 디렉토리 'app'을 컨테이너의 '/app' 경로에 연결하여 PySpark 스크립트를 사용할 수 있게 설정
      - ./metrics.properties:/opt/spark/conf/metrics.properties
    entrypoint:  # 컨테이너가 시작될 때 자동으로 실행할 명령어 지정
      - "/opt/spark/bin/spark-submit"
      - "--master"
      - "spark://spark-master:7077"  # Spark 마스터의 URL을 지정하여 Spark 클러스터 모드에서 실행
      - "--conf"
      - "spark.jars.ivy=/tmp/.ivy2"  # Ivy 캐시 경로를 /tmp/.ivy2로 설정하여 의존성 문제를 방지
      - "--conf"
      - "spark.metrics.conf=/opt/spark/conf/metrics.properties" # 메트릭스 수집을 위해 옵션 추가
      - "--files"
      - "/opt/spark/conf/metrics.properties"
      - "--executor-memory"
      - "512M"  # Executor 메모리를 512MB로 제한
      - "--total-executor-cores"
      - "1"  # 사용할 총 코어 수를 1개로 제한
      - "--num-executors"
      - "1"  # Executor의 수를 1개로 설정
      - "/app/pyspark_test.py"  # 실행할 PySpark 스크립트 파일 경로를 지정
    ports:
      - "4040:4040"
      
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"  # Prometheus Web UI
    environment:
      - TZ=Asia/Seoul
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml  # Prometheus 설정 파일
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
    networks:
      - spark-net  # 동일한 네트워크
    restart: always


  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin  # Grafana 관리자 비밀번호
      - TZ=Asia/Seoul # 호스트와 동일 시간대로 설정
    ports:
      - "3000:3000"  # Grafana Web UI
    depends_on:
      - prometheus
    networks:
      - spark-net  # 동일한 네트워크
    restart: always

networks:  # 서비스 간의 통신을 위한 네트워크 설정
  spark-net: # 네트워크 이름을 'spark-net'로 지정
    external: true
